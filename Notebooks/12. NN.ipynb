{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test and Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data_path = '/workspaces/Final-Year-Project/Cleaned Data/TrainTestData.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop('Diabetes Status', axis=1)\n",
    "y = df['Diabetes Status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä NN - Final dataset shape after scaling: (3268, 13)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Display the shape after scaling\n",
    "print(f\"üìä NN - Final dataset shape after scaling: {X_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Classifier setup\n",
    "nn = MLPClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (5, 5, 5),\n",
    "        (5,5,5,2),\n",
    "        (5,5,5,3),\n",
    "        (5,5,5,4),\n",
    "        (7,5,5,5)                                                                # Test a simpler structure with 3 layers\n",
    "    ],\n",
    "    'max_iter': [5000],  # Keep the same maximum iterations for convergence\n",
    "}\n",
    "\n",
    "\n",
    "# KFold cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV setup with F1-score as the scoring parameter\n",
    "grid_search = GridSearchCV(nn, param_grid, scoring='f1', cv=kf, n_jobs=-1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters for Neural Network: {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 5000}\n",
      "Best F1-Score with Best Parameters: 0.7635996548620713\n"
     ]
    }
   ],
   "source": [
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_nn = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters and the best score\n",
    "print(\"Best Parameters for Neural Network:\", grid_search.best_params_)\n",
    "print(\"Best F1-Score with Best Parameters:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå NN Classification Report on Training Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73      1638\n",
      "           1       0.72      0.83      0.77      1630\n",
      "\n",
      "    accuracy                           0.75      3268\n",
      "   macro avg       0.76      0.75      0.75      3268\n",
      "weighted avg       0.76      0.75      0.75      3268\n",
      "\n",
      "üü¶ NN - Confusion Matrix on Training Data:\n",
      "[[1102  536]\n",
      " [ 270 1360]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training data\n",
    "y_pred = best_nn.predict(X_scaled)\n",
    "\n",
    "# Classification report on the training data\n",
    "print(\"üìå NN Classification Report on Training Data:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "# Confusion matrix on the training data\n",
    "print(\"üü¶ NN - Confusion Matrix on Training Data:\")\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ NN - Validation dataset shape: (364, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "valid_path = \"/workspaces/Final-Year-Project/Cleaned Data/ValidationData.csv\"\n",
    "df_valid = pd.read_csv(valid_path)\n",
    "\n",
    "# Drop any rows with missing values in the validation set\n",
    "df_valid = df_valid.dropna()\n",
    "\n",
    "# Prepare features and target for validation data\n",
    "X_valid = df_valid.drop('Diabetes Status', axis=1)\n",
    "y_valid = df_valid['Diabetes Status']\n",
    "\n",
    "# Scale the validation data using the previously fitted scaler\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Display the shape of the validation dataset\n",
    "print(f\"üß™ NN - Validation dataset shape: {X_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on validation data\n",
    "y_pred_valid = best_nn.predict(X_valid_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå NN - Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74       178\n",
      "           1       0.74      0.85      0.79       186\n",
      "\n",
      "    accuracy                           0.77       364\n",
      "   macro avg       0.78      0.77      0.77       364\n",
      "weighted avg       0.78      0.77      0.77       364\n",
      "\n",
      "üü¶ NN - Validation Confusion Matrix:\n",
      "[[122  56]\n",
      " [ 28 158]]\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for validation data\n",
    "print(f\"üìå NN - Validation Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred_valid))\n",
    "\n",
    "# Print confusion matrix for validation data\n",
    "print(\"üü¶ NN - Validation Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, y_pred_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best Model Validation F1-Score: 0.7669512195121951\n"
     ]
    }
   ],
   "source": [
    "# Recalculate Macro average F1-score on validation data\n",
    "validation_f1_macro = f1_score(y_valid, y_pred_valid, average='macro')\n",
    "print(f\"üèÜ Best Model Validation F1-Score: {validation_f1_macro}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
