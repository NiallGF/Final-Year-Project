{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test and Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç LR - Original dataset shape: (3268, 14)\n",
      "üßπ LR - After dropping NaNs: (3268, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "data_path = '/workspaces/Final-Year-Project/Cleaned Data/TrainTestData.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display the original shape of the dataset\n",
    "print(f\"üîç LR - Original dataset shape: {df.shape}\")\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the shape after dropping NaNs\n",
    "print(f\"üßπ LR - After dropping NaNs: {df.shape}\")\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop('Diabetes Status', axis=1)\n",
    "y = df['Diabetes Status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LR - Final dataset shape after scaling: (3268, 13)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Display the shape after scaling\n",
    "print(f\"üìä LR - Final dataset shape after scaling: {X_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier setup\n",
    "lr = LogisticRegression(max_iter=80, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    #'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'max_iter': [100, 200, 500],  # Maximum iterations\n",
    "}\n",
    "\n",
    "# KFold cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV setup with accuracy as the scoring parameter\n",
    "grid_search = GridSearchCV(lr, param_grid, scoring='accuracy', cv=kf, n_jobs=-1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "‚úÖ LR - Best Parameters: {'max_iter': 100}\n",
      "‚úÖ LR - K-Fold Mean Accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_lr = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters and the best score\n",
    "print(f\"‚úÖ LR - Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"‚úÖ LR - K-Fold Mean Accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå LR Classification Report on Training Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73      1638\n",
      "           1       0.72      0.82      0.77      1630\n",
      "\n",
      "    accuracy                           0.75      3268\n",
      "   macro avg       0.76      0.75      0.75      3268\n",
      "weighted avg       0.76      0.75      0.75      3268\n",
      "\n",
      "üü¶ LR - Confusion Matrix on Training Data:\n",
      "[[1109  529]\n",
      " [ 289 1341]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training data\n",
    "y_pred = best_lr.predict(X_scaled)\n",
    "\n",
    "# Classification report on the training data\n",
    "print(\"üìå LR Classification Report on Training Data:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "# Confusion matrix on the training data\n",
    "print(\"üü¶ LR - Confusion Matrix on Training Data:\")\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ LR - Validation dataset shape: (364, 13)\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "valid_path = \"/workspaces/Final-Year-Project/Cleaned Data/ValidationData.csv\"\n",
    "df_valid = pd.read_csv(valid_path)\n",
    "\n",
    "# Drop any rows with missing values in the validation set\n",
    "df_valid = df_valid.dropna()\n",
    "\n",
    "# Prepare features and target for validation data\n",
    "X_valid = df_valid.drop('Diabetes Status', axis=1)\n",
    "y_valid = df_valid['Diabetes Status']\n",
    "\n",
    "# Scale the validation data using the previously fitted scaler\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "# Display the shape of the validation dataset\n",
    "print(f\"üß™ LR - Validation dataset shape: {X_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on validation data\n",
    "y_pred_valid = best_lr.predict(X_valid_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå LR - Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       178\n",
      "           1       0.73      0.83      0.78       186\n",
      "\n",
      "    accuracy                           0.76       364\n",
      "   macro avg       0.76      0.75      0.75       364\n",
      "weighted avg       0.76      0.76      0.75       364\n",
      "\n",
      "üü¶ LR - Validation Confusion Matrix:\n",
      "[[121  57]\n",
      " [ 32 154]]\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for validation data\n",
    "print(f\"üìå LR - Validation Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred_valid))\n",
    "\n",
    "# Print confusion matrix for validation data\n",
    "print(\"üü¶ LR - Validation Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, y_pred_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Model  Precision    Recall  F1-Score  Accuracy\n",
      "0                      AdaBoost (AB)   0.767212  0.752747  0.748389  0.752747\n",
      "1                 Neural Network(NN)   0.762241  0.755495  0.753238  0.755495\n",
      "2                  Decision Tree(DT)   0.748498  0.741758  0.739233  0.741758\n",
      "3  K Nearest Nearest Neighbours(KNN)   0.723548  0.722527  0.721802  0.722527\n",
      "4                 Neural Network(NN)   0.775001  0.769231  0.767458  0.769231\n",
      "5                  Decision Tree(DT)   0.748498  0.741758  0.739233  0.741758\n",
      "6  K Nearest Nearest Neighbours(KNN)   0.723548  0.722527  0.721802  0.722527\n",
      "7           Logistic Regression (LR)   0.759684  0.755495  0.753959  0.755495\n",
      "8           Logistic Regression (LR)   0.759684  0.755495  0.753959  0.755495\n",
      "9           Logistic Regression (LR)   0.759684  0.755495  0.753959  0.755495\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you already have y_valid (true labels) and y_pred_valid (predicted labels)\n",
    "# Example classification report for AdaBoost (AB)\n",
    "report = classification_report(y_valid, y_pred_valid, output_dict=True)\n",
    "\n",
    "# Extract weighted scores\n",
    "weighted_precision = report['weighted avg']['precision']\n",
    "weighted_recall = report['weighted avg']['recall']\n",
    "weighted_f1 = report['weighted avg']['f1-score']\n",
    "accuracy = report['accuracy']\n",
    "\n",
    "# Create a dictionary with the scores\n",
    "ab_results = {\n",
    "    'Model': 'Logistic Regression (LR)',\n",
    "    'Precision': weighted_precision,\n",
    "    'Recall': weighted_recall,\n",
    "    'F1-Score': weighted_f1,\n",
    "    'Accuracy': accuracy\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "ab_df = pd.DataFrame([ab_results])\n",
    "\n",
    "# Create a DataFrame to store results (if not already created)\n",
    "results_df = pd.read_csv(\"/workspaces/Final-Year-Project/Results/model_results.csv\")\n",
    "\n",
    "# Concatenate the new row to the DataFrame\n",
    "results_df = pd.concat([results_df, ab_df], ignore_index=True)\n",
    "\n",
    "# Print the DataFrame to confirm it's added\n",
    "print(results_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(\"/workspaces/Final-Year-Project/Results/model_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best Model Validation F1-Score: 0.7534682322859513\n"
     ]
    }
   ],
   "source": [
    "# Recalculate Macro average F1-score on validation data\n",
    "validation_f1_macro = f1_score(y_valid, y_pred_valid, average='macro')\n",
    "print(f\"üèÜ Best Model Validation F1-Score: {validation_f1_macro}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
